{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Data Prepocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from sklearn.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset \n",
    "data_train = pd.read_csv('train.csv', index_col=0)\n",
    "data_test = pd.read_csv('test.csv', index_col=0)\n",
    "\n",
    "# concat the training and testing dataset so that we can do preprocess \n",
    "# on both datasets simultaneously\n",
    "data = pd.concat( [data_train, data_test], axis=0,sort=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Split names and encode the object as an enumerated type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived      418\n",
      "Last Name       0\n",
      "Title           0\n",
      "Pclass          0\n",
      "Name            0\n",
      "Sex             0\n",
      "Age           263\n",
      "SibSp           0\n",
      "Parch           0\n",
      "Ticket          0\n",
      "Fare            1\n",
      "Cabin        1014\n",
      "Embarked        2\n",
      "dtype: int64\n",
      "{' Mr': 757, ' Mrs': 197, ' Miss': 260, ' Master': 61, ' Don': 1, ' Rev': 8, ' Dr': 8, ' Mme': 1, ' Ms': 2, ' Major': 2, ' Lady': 1, ' Sir': 1, ' Mlle': 2, ' Col': 4, ' Capt': 1, ' the Countess': 1, ' Jonkheer': 1, ' Dona': 1}\n",
      "(array([0, 1, 2, ..., 0, 0, 3], dtype=int64), Index(['Mr', 'Mrs', 'Miss', 'Master', 'DrAndRev'], dtype='object'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julien\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Julien\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Julien\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Julien\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Julien\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# split 'Name'\n",
    "## split ','\n",
    "data.insert(1,'Title',data['Name']) \n",
    "data['Name'] = data['Name'].map(lambda x:x.split(',')[0])\n",
    "data['Title'] = data['Title'].map(lambda x:x.split(',')[1])\n",
    "## split'.\n",
    "data.insert(1,'Last Name',data['Title']) \n",
    "data['Title'] = data['Title'].map(lambda x:x.split('.')[0])\n",
    "data['Last Name'] = data['Last Name'].map(lambda x:x.split('.')[1])\n",
    "\n",
    "# check missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "\n",
    "Title = data.loc[:,'Title'].unique()\n",
    "# Check the numbers for each title\n",
    "counts = {}\n",
    "for i in data.loc[:,'Title']:\n",
    "    if i in counts:\n",
    "        counts[i] +=1\n",
    "    else:\n",
    "        counts[i] = 1\n",
    "print(counts)\n",
    "\n",
    "# re-group to 5 main title:'Master','Miss','Mrs','Mr', 'DrAndRev'\n",
    "data['Title'] = data['Title'].map(str.strip) \n",
    "data['Title'][data.Title == 'Jonkheer'] = 'Master'\n",
    "data['Title'][data.Title.isin(['Ms','Mlle'])] = 'Miss'\n",
    "data['Title'][data.Title.isin(['Mme','Dona', 'Lady', 'the Countess'])] = 'Mrs'\n",
    "data['Title'][data.Title.isin(['Capt', 'Don', 'Major', 'Col', 'Sir'])] = 'Mr'\n",
    "data['Title'][data.Title.isin(['Dr','Rev'])] = 'DrAndRev'\n",
    "\n",
    "\n",
    "data.loc[:,'Title'].unique() # check again the unique values in Title\n",
    "# Factorize title: 'Mr'=1, 'Mrs'=2, 'Miss'=3, 'Master'=4, 'DrAndRev'=5\n",
    "title_trans = pd.factorize(data.Title) \n",
    "print(title_trans)\n",
    "data['Title'] = pd.factorize(data.Title)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Refill missing values in Embarked and create dummy varibale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refill 2 missing values for 'Embarked'\n",
    "Embarked_missing = data[data.loc[:,'Embarked'].isnull()] # get the rows with missing values\n",
    "\n",
    "# Looking at 'Ticket','Survived','Pclass', we find out that these two rows are more similar \n",
    "# to the rows with Embarked S than other rows.\n",
    "data.loc[data.loc[:,'Embarked'].isnull(),'Embarked'] = 'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived       418\n",
      "Last Name        0\n",
      "Title            0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            263\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin         1014\n",
      "Embarked         0\n",
      "Embarked_C       0\n",
      "Embarked_Q       0\n",
      "Embarked_S       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create dummy variables\n",
    "dummies = pd.get_dummies(data.loc[:,'Embarked'], prefix = 'Embarked')\n",
    "data = pd.concat([data,dummies],axis = 1)\n",
    "\n",
    "# check missing values again\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Refill missing values in Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived       418\n",
      "Last Name        0\n",
      "Title            0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            263\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin         1014\n",
      "Embarked         0\n",
      "Embarked_C       0\n",
      "Embarked_Q       0\n",
      "Embarked_S       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# refill 1 missing values for 'Fare'\n",
    "Fare_missing = data[data.loc[:,'Fare'].isnull()] # get the rows with missing values\n",
    "\n",
    "# We fill in the missing value with the mean of fares with Class 3 and Embarked S\n",
    "C3_ES_fare = data[(data['Pclass']==3) & (data['Embarked']=='S')].loc[:,'Fare']\n",
    "C3_ES_fare_mean = round(C3_ES_fare.mean(),2)\n",
    "data.loc[data.loc[:,'Fare'].isnull(),'Fare'] = C3_ES_fare_mean\n",
    "\n",
    "# check missing values again\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Refill missing values in Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julien\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Julien\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# refill 263 missing values for 'Age'\n",
    "# split the data into two part: known_age and unknown_age\n",
    "age_data = data.loc[:,['Age','Parch','SibSp','Pclass','Title']]\n",
    "known_age = age_data[age_data.Age.notnull()].as_matrix()\n",
    "unknown_age = age_data[age_data.Age.isnull()].as_matrix()\n",
    "y_knownage = known_age[:,0]\n",
    "X_knownage = known_age[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the RandomForestRegressor model\n",
    "rfr = RandomForestRegressor(random_state=0, n_estimators=200, n_jobs=-1)\n",
    "rfr.fit(X_knownage, y_knownage)\n",
    "\n",
    "# predict the unknown age\n",
    "predictedAges = rfr.predict(unknown_age[:, 1:])\n",
    "\n",
    "# refill the missing values\n",
    "data.loc[data.loc[:,'Age'].isnull(),'Age'] = predictedAges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Age_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Laina</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived                               Last Name  Title  Pclass  \\\n",
       "PassengerId                                                                    \n",
       "1                 0.0                             Owen Harris      0       3   \n",
       "2                 1.0   John Bradley (Florence Briggs Thayer)      1       1   \n",
       "3                 1.0                                   Laina      2       3   \n",
       "4                 1.0           Jacques Heath (Lily May Peel)      1       1   \n",
       "5                 0.0                           William Henry      0       3   \n",
       "\n",
       "                  Name     Sex   Age  SibSp  Parch            Ticket     Fare  \\\n",
       "PassengerId                                                                     \n",
       "1               Braund    male  22.0      1      0         A/5 21171   7.2500   \n",
       "2              Cumings  female  38.0      1      0          PC 17599  71.2833   \n",
       "3            Heikkinen  female  26.0      0      0  STON/O2. 3101282   7.9250   \n",
       "4             Futrelle  female  35.0      1      0            113803  53.1000   \n",
       "5                Allen    male  35.0      0      0            373450   8.0500   \n",
       "\n",
       "            Cabin Embarked  Embarked_C  Embarked_Q  Embarked_S  Age_cat  \n",
       "PassengerId                                                              \n",
       "1             NaN        S           0           0           1        1  \n",
       "2             C85        C           1           0           0        1  \n",
       "3             NaN        S           0           0           1        1  \n",
       "4            C123        S           0           0           1        1  \n",
       "5             NaN        S           0           0           1        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorize ages\n",
    "# 0 for teenager (0-18), 1 for adult(19-50), 2 for elder(51-)\n",
    "Age_cat = []\n",
    "for i in data.loc[:,'Age']:\n",
    "    if int(i) <= 18:\n",
    "        Age_cat.append(0)\n",
    "    elif int(i) >18 and int(i) <= 50:\n",
    "        Age_cat.append(1)\n",
    "    else:\n",
    "        Age_cat.append(2)\n",
    "data['Age_cat'] = Age_cat\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived       418\n",
      "Last Name        0\n",
      "Title            0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin         1014\n",
      "Embarked         0\n",
      "Embarked_C       0\n",
      "Embarked_Q       0\n",
      "Embarked_S       0\n",
      "Age_cat          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check missing values again\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Factorize values in Sex (male = 0, female = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 1, ..., 0, 0, 0], dtype=int64), Index(['male', 'female'], dtype='object'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Age_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Laina</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived                               Last Name  Title  Pclass  \\\n",
       "PassengerId                                                                    \n",
       "1                 0.0                             Owen Harris      0       3   \n",
       "2                 1.0   John Bradley (Florence Briggs Thayer)      1       1   \n",
       "3                 1.0                                   Laina      2       3   \n",
       "4                 1.0           Jacques Heath (Lily May Peel)      1       1   \n",
       "5                 0.0                           William Henry      0       3   \n",
       "\n",
       "                  Name  Sex   Age  SibSp  Parch            Ticket     Fare  \\\n",
       "PassengerId                                                                  \n",
       "1               Braund    0  22.0      1      0         A/5 21171   7.2500   \n",
       "2              Cumings    1  38.0      1      0          PC 17599  71.2833   \n",
       "3            Heikkinen    1  26.0      0      0  STON/O2. 3101282   7.9250   \n",
       "4             Futrelle    1  35.0      1      0            113803  53.1000   \n",
       "5                Allen    0  35.0      0      0            373450   8.0500   \n",
       "\n",
       "            Cabin Embarked  Embarked_C  Embarked_Q  Embarked_S  Age_cat  \n",
       "PassengerId                                                              \n",
       "1             NaN        S           0           0           1        1  \n",
       "2             C85        C           1           0           0        1  \n",
       "3             NaN        S           0           0           1        1  \n",
       "4            C123        S           0           0           1        1  \n",
       "5             NaN        S           0           0           1        1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check again the unique values in sex\n",
    "data.loc[:,'Sex'].unique() \n",
    "# factorize values in Sex: 'Male'=0, 'Female'=1\n",
    "Sex_trans = pd.factorize(data.Sex) \n",
    "print(Sex_trans)\n",
    "data['Sex'] = pd.factorize(data.Sex)[0]\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize Fare\n",
    "max_fare = data.Fare.max()\n",
    "min_fare = data.Fare.min()\n",
    "range_fare = max_fare - min_fare\n",
    "\n",
    "#1 for fare 0-10, 2 for fare 10-100, 3 for fare 100 and more\n",
    "fare_cat = []\n",
    "for i in data.loc[:,'Fare']:\n",
    "    if i <= 10:\n",
    "        fare_cat.append(1)\n",
    "    elif i >10 and i <= 100:\n",
    "        fare_cat.append(2)\n",
    "    else:\n",
    "        fare_cat.append(3)\n",
    "\n",
    "data['Fare'] = fare_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Generate new feature 'FamilySize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Age_cat</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>2</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Laina</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>2</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived                               Last Name  Title  Pclass  \\\n",
       "PassengerId                                                                    \n",
       "1                 0.0                             Owen Harris      0       3   \n",
       "2                 1.0   John Bradley (Florence Briggs Thayer)      1       1   \n",
       "3                 1.0                                   Laina      2       3   \n",
       "4                 1.0           Jacques Heath (Lily May Peel)      1       1   \n",
       "5                 0.0                           William Henry      0       3   \n",
       "\n",
       "                  Name  Sex   Age  SibSp  Parch            Ticket  Fare Cabin  \\\n",
       "PassengerId                                                                     \n",
       "1               Braund    0  22.0      1      0         A/5 21171     1   NaN   \n",
       "2              Cumings    1  38.0      1      0          PC 17599     2   C85   \n",
       "3            Heikkinen    1  26.0      0      0  STON/O2. 3101282     1   NaN   \n",
       "4             Futrelle    1  35.0      1      0            113803     2  C123   \n",
       "5                Allen    0  35.0      0      0            373450     1   NaN   \n",
       "\n",
       "            Embarked  Embarked_C  Embarked_Q  Embarked_S  Age_cat  FamilySize  \n",
       "PassengerId                                                                    \n",
       "1                  S           0           0           1        1           1  \n",
       "2                  C           1           0           0        1           1  \n",
       "3                  S           0           0           1        1           0  \n",
       "4                  S           0           0           1        1           1  \n",
       "5                  S           0           0           1        1           0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new features called number of companions\n",
    "data['FamilySize'] = data['SibSp'] + data['Parch']\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Generate new feature 'Companions '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Age_cat</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Companions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>2</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Laina</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>2</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>James</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran</td>\n",
       "      <td>0</td>\n",
       "      <td>28.484979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Timothy J</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy</td>\n",
       "      <td>0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>2</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Gosta Leonard</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Nicholas (Adele Achem)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Marguerite Rut</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>2</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell</td>\n",
       "      <td>1</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>2</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Anders Johan</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson</td>\n",
       "      <td>0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Hulda Amanda Adolfina</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(Mary D Kingcome)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett</td>\n",
       "      <td>1</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Eugene</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Charles Eugene</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams</td>\n",
       "      <td>0</td>\n",
       "      <td>32.086885</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Julius (Emelia Maria Vandemoortele)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke</td>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Fatima</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani</td>\n",
       "      <td>1</td>\n",
       "      <td>39.237843</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Joseph J</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley</td>\n",
       "      <td>0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>2</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Anna \"Annie\"</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>William Thompson</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper</td>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>2</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Torborg Danira</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Carl Oscar (Selma Augusta Emilia Johansson)</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Farred Chehab</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir</td>\n",
       "      <td>0</td>\n",
       "      <td>28.484979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Charles Alexander</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>3</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Ellen \"Nellie\"</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer</td>\n",
       "      <td>1</td>\n",
       "      <td>22.851767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Lalio</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff</td>\n",
       "      <td>0</td>\n",
       "      <td>28.484979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Canavan</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364858</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Paul Folke</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Vivian Ponsonby</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Payne</td>\n",
       "      <td>0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12749</td>\n",
       "      <td>2</td>\n",
       "      <td>B24</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ernest H (Elizabeth Lindsey James)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Lines</td>\n",
       "      <td>1</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17592</td>\n",
       "      <td>2</td>\n",
       "      <td>D28</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Eugene Joseph</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>C.A. 2673</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>NaN</td>\n",
       "      <td>William</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 30769</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Anton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kink-Heilmann</td>\n",
       "      <td>0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>315153</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Lucien Philip (Mary Eloise Hughes)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Smith</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13695</td>\n",
       "      <td>2</td>\n",
       "      <td>C31</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Patrick</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Colbert</td>\n",
       "      <td>0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>371109</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Maxmillian (Margaretha Emerentia Stehli)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Frolicher-Stehli</td>\n",
       "      <td>1</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13567</td>\n",
       "      <td>2</td>\n",
       "      <td>B41</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Edvard A</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Larsson-Rondberg</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347065</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Thomas Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Conlon</td>\n",
       "      <td>0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21332</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Caroline</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell</td>\n",
       "      <td>1</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36928</td>\n",
       "      <td>3</td>\n",
       "      <td>C7</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Harry</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gale</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28664</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Dorothy Winifred</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Gibson</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112378</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Jose Pedro</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carrau</td>\n",
       "      <td>0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113059</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Isaac Gerald</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Frauenthal</td>\n",
       "      <td>0</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17765</td>\n",
       "      <td>2</td>\n",
       "      <td>D40</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Alfred (Baron von Drachstedt\")\"</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Nourney</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2166</td>\n",
       "      <td>2</td>\n",
       "      <td>D38</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>NaN</td>\n",
       "      <td>William Jeffery</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ware</td>\n",
       "      <td>0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28666</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>NaN</td>\n",
       "      <td>George Dunton</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Widener</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113503</td>\n",
       "      <td>3</td>\n",
       "      <td>C80</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Johanna Hannah\"\"</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Riordan</td>\n",
       "      <td>1</td>\n",
       "      <td>22.851767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>334915</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Treasteall</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Peacock</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SOTON/O.Q. 3101315</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hannah</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Naughton</td>\n",
       "      <td>1</td>\n",
       "      <td>22.851767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>365237</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>NaN</td>\n",
       "      <td>William Edward (Lillian E Thorpe)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Minahan</td>\n",
       "      <td>1</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19928</td>\n",
       "      <td>2</td>\n",
       "      <td>C78</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Jenny Lovisa</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Henriksson</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347086</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Woolf</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector</td>\n",
       "      <td>0</td>\n",
       "      <td>28.484979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Fermina</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana</td>\n",
       "      <td>1</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>3</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Simon Sivertsen</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether</td>\n",
       "      <td>0</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Frederick</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware</td>\n",
       "      <td>0</td>\n",
       "      <td>28.484979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Michael J</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter</td>\n",
       "      <td>0</td>\n",
       "      <td>5.729525</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived                                     Last Name  Title  \\\n",
       "PassengerId                                                                  \n",
       "1                 0.0                                   Owen Harris      0   \n",
       "2                 1.0         John Bradley (Florence Briggs Thayer)      1   \n",
       "3                 1.0                                         Laina      2   \n",
       "4                 1.0                 Jacques Heath (Lily May Peel)      1   \n",
       "5                 0.0                                 William Henry      0   \n",
       "6                 0.0                                         James      0   \n",
       "7                 0.0                                     Timothy J      0   \n",
       "8                 0.0                                 Gosta Leonard      3   \n",
       "9                 1.0           Oscar W (Elisabeth Vilhelmina Berg)      1   \n",
       "10                1.0                        Nicholas (Adele Achem)      1   \n",
       "11                1.0                                Marguerite Rut      2   \n",
       "12                1.0                                     Elizabeth      2   \n",
       "13                0.0                                 William Henry      0   \n",
       "14                0.0                                  Anders Johan      0   \n",
       "15                0.0                         Hulda Amanda Adolfina      2   \n",
       "16                1.0                            (Mary D Kingcome)       1   \n",
       "17                0.0                                        Eugene      3   \n",
       "18                1.0                                Charles Eugene      0   \n",
       "19                0.0           Julius (Emelia Maria Vandemoortele)      1   \n",
       "20                1.0                                        Fatima      1   \n",
       "21                0.0                                      Joseph J      0   \n",
       "22                1.0                                      Lawrence      0   \n",
       "23                1.0                                  Anna \"Annie\"      2   \n",
       "24                1.0                              William Thompson      0   \n",
       "25                0.0                                Torborg Danira      2   \n",
       "26                1.0   Carl Oscar (Selma Augusta Emilia Johansson)      1   \n",
       "27                0.0                                 Farred Chehab      0   \n",
       "28                0.0                             Charles Alexander      0   \n",
       "29                1.0                                Ellen \"Nellie\"      2   \n",
       "30                0.0                                         Lalio      0   \n",
       "...               ...                                           ...    ...   \n",
       "1280              NaN                                       Patrick      0   \n",
       "1281              NaN                                    Paul Folke      3   \n",
       "1282              NaN                               Vivian Ponsonby      0   \n",
       "1283              NaN            Ernest H (Elizabeth Lindsey James)      1   \n",
       "1284              NaN                                 Eugene Joseph      3   \n",
       "1285              NaN                                       William      0   \n",
       "1286              NaN                                         Anton      0   \n",
       "1287              NaN            Lucien Philip (Mary Eloise Hughes)      1   \n",
       "1288              NaN                                       Patrick      0   \n",
       "1289              NaN      Maxmillian (Margaretha Emerentia Stehli)      1   \n",
       "1290              NaN                                      Edvard A      0   \n",
       "1291              NaN                                  Thomas Henry      0   \n",
       "1292              NaN                                      Caroline      2   \n",
       "1293              NaN                                         Harry      0   \n",
       "1294              NaN                              Dorothy Winifred      2   \n",
       "1295              NaN                                    Jose Pedro      0   \n",
       "1296              NaN                                  Isaac Gerald      0   \n",
       "1297              NaN               Alfred (Baron von Drachstedt\")\"      0   \n",
       "1298              NaN                               William Jeffery      0   \n",
       "1299              NaN                                 George Dunton      0   \n",
       "1300              NaN                              Johanna Hannah\"\"      2   \n",
       "1301              NaN                                    Treasteall      2   \n",
       "1302              NaN                                        Hannah      2   \n",
       "1303              NaN             William Edward (Lillian E Thorpe)      1   \n",
       "1304              NaN                                  Jenny Lovisa      2   \n",
       "1305              NaN                                         Woolf      0   \n",
       "1306              NaN                                       Fermina      1   \n",
       "1307              NaN                               Simon Sivertsen      0   \n",
       "1308              NaN                                     Frederick      0   \n",
       "1309              NaN                                     Michael J      3   \n",
       "\n",
       "             Pclass              Name  Sex        Age  SibSp  Parch  \\\n",
       "PassengerId                                                           \n",
       "1                 3            Braund    0  22.000000      1      0   \n",
       "2                 1           Cumings    1  38.000000      1      0   \n",
       "3                 3         Heikkinen    1  26.000000      0      0   \n",
       "4                 1          Futrelle    1  35.000000      1      0   \n",
       "5                 3             Allen    0  35.000000      0      0   \n",
       "6                 3             Moran    0  28.484979      0      0   \n",
       "7                 1          McCarthy    0  54.000000      0      0   \n",
       "8                 3           Palsson    0   2.000000      3      1   \n",
       "9                 3           Johnson    1  27.000000      0      2   \n",
       "10                2            Nasser    1  14.000000      1      0   \n",
       "11                3         Sandstrom    1   4.000000      1      1   \n",
       "12                1           Bonnell    1  58.000000      0      0   \n",
       "13                3       Saundercock    0  20.000000      0      0   \n",
       "14                3         Andersson    0  39.000000      1      5   \n",
       "15                3           Vestrom    1  14.000000      0      0   \n",
       "16                2           Hewlett    1  55.000000      0      0   \n",
       "17                3              Rice    0   2.000000      4      1   \n",
       "18                2          Williams    0  32.086885      0      0   \n",
       "19                3     Vander Planke    1  31.000000      1      0   \n",
       "20                3        Masselmani    1  39.237843      0      0   \n",
       "21                2            Fynney    0  35.000000      0      0   \n",
       "22                2           Beesley    0  34.000000      0      0   \n",
       "23                3           McGowan    1  15.000000      0      0   \n",
       "24                1            Sloper    0  28.000000      0      0   \n",
       "25                3           Palsson    1   8.000000      3      1   \n",
       "26                3           Asplund    1  38.000000      1      5   \n",
       "27                3              Emir    0  28.484979      0      0   \n",
       "28                1           Fortune    0  19.000000      3      2   \n",
       "29                3           O'Dwyer    1  22.851767      0      0   \n",
       "30                3          Todoroff    0  28.484979      0      0   \n",
       "...             ...               ...  ...        ...    ...    ...   \n",
       "1280              3           Canavan    0  21.000000      0      0   \n",
       "1281              3           Palsson    0   6.000000      3      1   \n",
       "1282              1             Payne    0  23.000000      0      0   \n",
       "1283              1             Lines    1  51.000000      0      1   \n",
       "1284              3            Abbott    0  13.000000      0      2   \n",
       "1285              2           Gilbert    0  47.000000      0      0   \n",
       "1286              3     Kink-Heilmann    0  29.000000      3      1   \n",
       "1287              1             Smith    1  18.000000      1      0   \n",
       "1288              3           Colbert    0  24.000000      0      0   \n",
       "1289              1  Frolicher-Stehli    1  48.000000      1      1   \n",
       "1290              3  Larsson-Rondberg    0  22.000000      0      0   \n",
       "1291              3            Conlon    0  31.000000      0      0   \n",
       "1292              1           Bonnell    1  30.000000      0      0   \n",
       "1293              2              Gale    0  38.000000      1      0   \n",
       "1294              1            Gibson    1  22.000000      0      1   \n",
       "1295              1            Carrau    0  17.000000      0      0   \n",
       "1296              1        Frauenthal    0  43.000000      1      0   \n",
       "1297              2           Nourney    0  20.000000      0      0   \n",
       "1298              2              Ware    0  23.000000      1      0   \n",
       "1299              1           Widener    0  50.000000      1      1   \n",
       "1300              3           Riordan    1  22.851767      0      0   \n",
       "1301              3           Peacock    1   3.000000      1      1   \n",
       "1302              3          Naughton    1  22.851767      0      0   \n",
       "1303              1           Minahan    1  37.000000      1      0   \n",
       "1304              3        Henriksson    1  28.000000      0      0   \n",
       "1305              3           Spector    0  28.484979      0      0   \n",
       "1306              1     Oliva y Ocana    1  39.000000      0      0   \n",
       "1307              3           Saether    0  38.500000      0      0   \n",
       "1308              3              Ware    0  28.484979      0      0   \n",
       "1309              3             Peter    0   5.729525      1      1   \n",
       "\n",
       "                         Ticket  Fare        Cabin Embarked  Embarked_C  \\\n",
       "PassengerId                                                               \n",
       "1                     A/5 21171     1          NaN        S           0   \n",
       "2                      PC 17599     2          C85        C           1   \n",
       "3              STON/O2. 3101282     1          NaN        S           0   \n",
       "4                        113803     2         C123        S           0   \n",
       "5                        373450     1          NaN        S           0   \n",
       "6                        330877     1          NaN        Q           0   \n",
       "7                         17463     2          E46        S           0   \n",
       "8                        349909     2          NaN        S           0   \n",
       "9                        347742     2          NaN        S           0   \n",
       "10                       237736     2          NaN        C           1   \n",
       "11                      PP 9549     2           G6        S           0   \n",
       "12                       113783     2         C103        S           0   \n",
       "13                    A/5. 2151     1          NaN        S           0   \n",
       "14                       347082     2          NaN        S           0   \n",
       "15                       350406     1          NaN        S           0   \n",
       "16                       248706     2          NaN        S           0   \n",
       "17                       382652     2          NaN        Q           0   \n",
       "18                       244373     2          NaN        S           0   \n",
       "19                       345763     2          NaN        S           0   \n",
       "20                         2649     1          NaN        C           1   \n",
       "21                       239865     2          NaN        S           0   \n",
       "22                       248698     2          D56        S           0   \n",
       "23                       330923     1          NaN        Q           0   \n",
       "24                       113788     2           A6        S           0   \n",
       "25                       349909     2          NaN        S           0   \n",
       "26                       347077     2          NaN        S           0   \n",
       "27                         2631     1          NaN        C           1   \n",
       "28                        19950     3  C23 C25 C27        S           0   \n",
       "29                       330959     1          NaN        Q           0   \n",
       "30                       349216     1          NaN        S           0   \n",
       "...                         ...   ...          ...      ...         ...   \n",
       "1280                     364858     1          NaN        Q           0   \n",
       "1281                     349909     2          NaN        S           0   \n",
       "1282                      12749     2          B24        S           0   \n",
       "1283                   PC 17592     2          D28        S           0   \n",
       "1284                  C.A. 2673     2          NaN        S           0   \n",
       "1285                 C.A. 30769     2          NaN        S           0   \n",
       "1286                     315153     2          NaN        S           0   \n",
       "1287                      13695     2          C31        S           0   \n",
       "1288                     371109     1          NaN        Q           0   \n",
       "1289                      13567     2          B41        C           1   \n",
       "1290                     347065     1          NaN        S           0   \n",
       "1291                      21332     1          NaN        Q           0   \n",
       "1292                      36928     3           C7        S           0   \n",
       "1293                      28664     2          NaN        S           0   \n",
       "1294                     112378     2          NaN        C           1   \n",
       "1295                     113059     2          NaN        S           0   \n",
       "1296                      17765     2          D40        C           1   \n",
       "1297              SC/PARIS 2166     2          D38        C           1   \n",
       "1298                      28666     2          NaN        S           0   \n",
       "1299                     113503     3          C80        C           1   \n",
       "1300                     334915     1          NaN        Q           0   \n",
       "1301         SOTON/O.Q. 3101315     2          NaN        S           0   \n",
       "1302                     365237     1          NaN        Q           0   \n",
       "1303                      19928     2          C78        Q           0   \n",
       "1304                     347086     1          NaN        S           0   \n",
       "1305                  A.5. 3236     1          NaN        S           0   \n",
       "1306                   PC 17758     3         C105        C           1   \n",
       "1307         SOTON/O.Q. 3101262     1          NaN        S           0   \n",
       "1308                     359309     1          NaN        S           0   \n",
       "1309                       2668     2          NaN        C           1   \n",
       "\n",
       "             Embarked_Q  Embarked_S  Age_cat  FamilySize  Companions  \n",
       "PassengerId                                                           \n",
       "1                     0           1        1           1           1  \n",
       "2                     0           0        1           1           2  \n",
       "3                     0           1        1           0           1  \n",
       "4                     0           1        1           1           2  \n",
       "5                     0           1        1           0           1  \n",
       "6                     1           0        1           0           1  \n",
       "7                     0           1        2           0           2  \n",
       "8                     0           1        0           4           3  \n",
       "9                     0           1        1           2           3  \n",
       "10                    0           0        0           1           2  \n",
       "11                    0           1        0           2           3  \n",
       "12                    0           1        2           0           1  \n",
       "13                    0           1        1           0           1  \n",
       "14                    0           1        1           6           3  \n",
       "15                    0           1        0           0           1  \n",
       "16                    0           1        2           0           1  \n",
       "17                    1           0        0           5           3  \n",
       "18                    0           1        1           0           1  \n",
       "19                    0           1        1           1           2  \n",
       "20                    0           0        1           0           1  \n",
       "21                    0           1        1           0           2  \n",
       "22                    0           1        1           0           1  \n",
       "23                    1           0        0           0           1  \n",
       "24                    0           1        1           0           1  \n",
       "25                    0           1        0           4           3  \n",
       "26                    0           1        1           6           3  \n",
       "27                    0           0        1           0           1  \n",
       "28                    0           1        1           5           3  \n",
       "29                    1           0        1           0           1  \n",
       "30                    0           1        1           0           1  \n",
       "...                 ...         ...      ...         ...         ...  \n",
       "1280                  1           0        1           0           1  \n",
       "1281                  0           1        0           4           3  \n",
       "1282                  0           1        1           0           3  \n",
       "1283                  0           1        2           1           2  \n",
       "1284                  0           1        0           2           3  \n",
       "1285                  0           1        1           0           1  \n",
       "1286                  0           1        1           4           3  \n",
       "1287                  0           1        0           1           2  \n",
       "1288                  1           0        1           0           1  \n",
       "1289                  0           0        1           2           2  \n",
       "1290                  0           1        1           0           1  \n",
       "1291                  1           0        1           0           1  \n",
       "1292                  0           1        1           0           3  \n",
       "1293                  0           1        1           1           2  \n",
       "1294                  0           0        1           1           2  \n",
       "1295                  0           1        0           0           2  \n",
       "1296                  0           0        1           1           1  \n",
       "1297                  0           0        1           0           1  \n",
       "1298                  0           1        1           1           1  \n",
       "1299                  0           0        1           2           3  \n",
       "1300                  1           0        1           0           1  \n",
       "1301                  0           1        0           2           3  \n",
       "1302                  1           0        1           0           1  \n",
       "1303                  1           0        1           1           3  \n",
       "1304                  0           1        1           0           1  \n",
       "1305                  0           1        1           0           1  \n",
       "1306                  0           0        1           0           3  \n",
       "1307                  0           1        1           0           1  \n",
       "1308                  0           1        1           0           1  \n",
       "1309                  0           0        0           2           3  \n",
       "\n",
       "[1309 rows x 19 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ticket = data.loc[:,'Ticket'].unique()\n",
    "# Check the numbers for each ticket number\n",
    "counts_ticket = {}\n",
    "for i in data.loc[:,'Ticket']:\n",
    "    if i in counts_ticket:\n",
    "        counts_ticket[i] +=1\n",
    "    else:\n",
    "        counts_ticket[i] = 1\n",
    "        \n",
    "# Find the number of companions for each passengers\n",
    "Companions = []\n",
    "for i in data.loc[:,'Ticket']:\n",
    "    if i in counts_ticket:\n",
    "        Companions.append(counts_ticket[i])\n",
    "# Add the new feature 'Companions' to the dataset\n",
    "data['Companions'] = Companions\n",
    "\n",
    "# Regrouping all person accompanied by more than 2 people\n",
    "# So that 1='alone', 2='1companions', 3='2 or more companions'\n",
    "for i in range(data.shape[0]):\n",
    "    if data.iloc[i,18] >= 3:\n",
    "        data.iloc[i,18] = 3\n",
    "        \n",
    "\n",
    "\n",
    "data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Remove columns and create training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Age_cat</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Companions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Title  Pclass  Sex  Fare  Embarked_C  Embarked_S  \\\n",
       "PassengerId                                                               \n",
       "1                 0.0      0       3    0     1           0           1   \n",
       "2                 1.0      1       1    1     2           1           0   \n",
       "3                 1.0      2       3    1     1           0           1   \n",
       "4                 1.0      1       1    1     2           0           1   \n",
       "5                 0.0      0       3    0     1           0           1   \n",
       "\n",
       "             Age_cat  FamilySize  Companions  \n",
       "PassengerId                                   \n",
       "1                  1           1           1  \n",
       "2                  1           1           2  \n",
       "3                  1           0           1  \n",
       "4                  1           1           2  \n",
       "5                  1           0           1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove 'Cabin', 'Ticket','Name','Last Name'\n",
    "data_drop = data.drop(['Ticket','Name','Last Name','Embarked','Embarked_Q','SibSp','Parch','Age','Cabin'],axis=1)\n",
    "data_drop.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Age_cat</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Companions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Title  Pclass  Sex  Fare  Embarked_C  Embarked_S  Age_cat  \\\n",
       "PassengerId                                                              \n",
       "1                0       3    0     1           0           1        1   \n",
       "2                1       1    1     2           1           0        1   \n",
       "3                2       3    1     1           0           1        1   \n",
       "4                1       1    1     2           0           1        1   \n",
       "5                0       3    0     1           0           1        1   \n",
       "\n",
       "             FamilySize  Companions  \n",
       "PassengerId                          \n",
       "1                     1           1  \n",
       "2                     1           2  \n",
       "3                     0           1  \n",
       "4                     1           2  \n",
       "5                     0           1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create training and testing dataset\n",
    "train_X = data_drop.iloc[0:891,1:10]\n",
    "train_y = data_drop.iloc[0:891,0]\n",
    "test_X = data_drop.iloc[891:,1:10]\n",
    "train_X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Feature Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type <class 'float'> cannot be safely interpreted as an integer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[1;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-288543cd034f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiverging_palette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m220\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mas_cmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcenter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquare\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mannot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Correlation matrix'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\palettes.py\u001b[0m in \u001b[0;36mdiverging_palette\u001b[1;34m(h_neg, h_pos, s, l, sep, n, center, as_cmap)\u001b[0m\n\u001b[0;32m    742\u001b[0m     \"\"\"\n\u001b[0;32m    743\u001b[0m     \u001b[0mpalfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdark_palette\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcenter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"dark\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlight_palette\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m     \u001b[0mneg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpalfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_neg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"husl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    745\u001b[0m     \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpalfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"husl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     midpoint = dict(light=[(.95, .95, .95, 1.)],\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\palettes.py\u001b[0m in \u001b[0;36mlight_palette\u001b[1;34m(color, n_colors, reverse, as_cmap, input)\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[0mlight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_hls_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.95\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlight\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mblend_palette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_colors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_cmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\palettes.py\u001b[0m in \u001b[0;36mblend_palette\u001b[1;34m(colors, n_colors, as_cmap, input)\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[0mpal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearSegmentedColormap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mas_cmap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m         \u001b[0mpal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ColorPalette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_colors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlinspace\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[1;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[0;32m    119\u001b[0m         raise TypeError(\n\u001b[0;32m    120\u001b[0m             \u001b[1;34m\"object of type {} cannot be safely interpreted as an integer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 .format(type(num)))\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type <class 'float'> cannot be safely interpreted as an integer."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 936x936 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw heatmap to learn about the correlation among all the features and class labels\n",
    "corr_list = data_drop.iloc[0:891,0:10]\n",
    "corr = ['Survived','Title','Pclass','Sex','Fare','Embarked_C','Embarked_S','Age_cat','FamilySize','Companions']\n",
    "corr_matrix = corr_list[corr].corr()\n",
    "\n",
    "fig = plt.figure(figsize=(13,13))\n",
    "cmap = sns.diverging_palette(220,10,as_cmap=True)\n",
    "ax = sns.heatmap(corr_matrix, cmap=cmap, vmax=1,center = 0.5, square=True,linewidths=.5,annot = True)\n",
    "ax.set_title('Correlation matrix',fontsize=20)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "corr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 'Sex', 'Title', 'Pclass', 'Fare', 'Companions' have relatively high correlation with Survived, we decide to take a look at their distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Sex vs Survived\n",
    "g = sns.factorplot(x='Sex', y='Survived', data = corr_list, kind='bar',size = 4, palette = 'muted')\n",
    "g.despine(left = True)\n",
    "g = g.set_ylabels('Survived probability')\n",
    "g.set_xticklabels(('Male', 'Female'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Title vs Survived\n",
    "g = sns.factorplot(x='Title', y='Survived', data = corr_list, kind='bar',size = 4, palette = 'muted')\n",
    "g.despine(left = True)\n",
    "g = g.set_ylabels('Survived probability')\n",
    "g.set_xticklabels(('Mr', 'Mrs', 'Miss', 'Master', 'DrAndRev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Pclass vs Survived\n",
    "g = sns.factorplot(x='Pclass', y='Survived', data = corr_list, kind='bar',size = 4, palette = 'muted')\n",
    "g.despine(left = True)\n",
    "g = g.set_ylabels('Survived probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Fare vs Survived\n",
    "g = sns.factorplot(x='Fare', y='Survived', data = corr_list, kind='bar',size = 4, palette = 'muted')\n",
    "g.despine(left = True)\n",
    "g = g.set_ylabels('Survived probability')\n",
    "g.set_xticklabels(('Low', 'Medium','High'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Companions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Companions vs Survived\n",
    "g = sns.factorplot(x='Companions', y='Survived', data = corr_list, kind='bar',size = 4, palette = 'muted')\n",
    "g.despine(left = True)\n",
    "g = g.set_ylabels('Survived probability')\n",
    "g.set_xticklabels(('Alone', 'OneCompan','2andMoreCompan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3  Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define a function to generate csv file \n",
    "def predict_csv(predic_y, model_name):\n",
    "    PassengerId = pd.Series(range(892,1310))\n",
    "    test_survived = pd.concat([PassengerId, pd.Series(predic_y)],axis =1)\n",
    "    test_survived.columns = ['PassengerId','Survived']\n",
    "    test_survived.to_csv('predicted_class_%s.csv'% model_name, index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Desicion tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data standardization and transformation \n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_X)\n",
    "train_X_transformed = scaler.transform(train_X)\n",
    "test_X_transformed = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Testing the model in the training phase\n",
    "cv_DS = StratifiedKFold(n_splits =10)\n",
    "clf_DS = DecisionTreeClassifier()\n",
    "scores_DS = cross_val_score(clf_DS, train_X, train_y, cv=cv_DS)\n",
    "accu_dt = scores_DS.mean()\n",
    "print('Accuracy: %0.2f (+/- %0.2f)' % (scores_DS.mean(),scores_DS.std()*2))\n",
    "\n",
    "# Train the model using the whole training dataset\n",
    "clf_DS = DecisionTreeClassifier().fit(train_X, train_y)\n",
    "\n",
    "# Predict the labels in test_X\n",
    "y_pred_dt = clf_DS.predict(test_X).astype(int)\n",
    "\n",
    "# stroe it in the csv file\n",
    "predict_csv(y_pred_dt, 'DT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "clf_rf = RandomForestClassifier(bootstrap = True, max_depth = 5)\n",
    "kf = KFold(891, n_folds = 10)\n",
    "outcomes = []\n",
    "fold = 0\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    fold +=1\n",
    "    X_train, X_test = train_X.values[train_index], train_X.values[test_index]\n",
    "    y_train, y_test = train_y.values[train_index], train_y.values[test_index]\n",
    "    \n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    predictions = clf_rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    outcomes.append(accuracy)\n",
    "    print('Fold {0} accuracy: {1}'.format(fold,round(accuracy,3)))\n",
    "    \n",
    "accu_rf = mean(outcomes)\n",
    "print('Mean Accuracy: {0}'.format(round(accu_rf,3)))\n",
    "\n",
    "y_pred_rf = clf_rf.predict(test_X).astype(int)\n",
    "\n",
    "# store it in the csv file\n",
    "predict_csv(y_pred_rf,'rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Testing the model in the training phase\n",
    "cv_LR = StratifiedKFold(n_splits =10)\n",
    "logreg = LogisticRegression()\n",
    "scores_LR = cross_val_score(logreg, train_X, train_y, cv=cv_LR)\n",
    "print(scores_LR)\n",
    "print(mean(scores_LR))\n",
    "print('Accuracy: %0.2f (+/- %0.2f)' % (scores_LR.mean(),scores_LR.std()*2))\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_X, train_y, test_size = 0.22, random_state = 0)\n",
    "\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_val)\n",
    "accu_logreg = scores_LR.mean()\n",
    "print(accu_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test set: y_pred\n",
    "y_pred_logicRe = logreg.predict(test_X).astype(int)\n",
    "\n",
    "# stroe it in the csv file\n",
    "predict_csv(y_pred_logicRe,'LogicRe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Setup arrays to store train and test accuracies\n",
    "neighbors = np.arange(1,20)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "scores_knn = np.empty(len(neighbors))\n",
    "cv_knn = StratifiedKFold(n_splits =10)\n",
    "#Loop over different values of k to find best value of k\n",
    "for i, k in enumerate(neighbors):\n",
    "    #Setup a k-nn Classifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    \n",
    "    #Fit the classifier to the training data\n",
    "    knn.fit(train_X, train_y)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(train_X, train_y)\n",
    "    print(train_accuracy[i])\n",
    "    scores_knn[i]= mean(cross_val_score(knn, train_X, train_y, cv=cv_knn, scoring = \"accuracy\"))\n",
    "    print('Accuracy: %0.2f (+/- %0.2f)' % (scores_knn.mean(),scores_knn.std()*2))\n",
    "\n",
    "    \n",
    "    \n",
    "MSE = [1 - x for x in scores_knn]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print(\"The optimal number of neighbors is %d\" % optimal_k)\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(neighbors, MSE)\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate plot to visualize best value of k\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, scores_knn, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verification number 95684520... because not sure about optimal number of k\n",
    "#Verification using GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"n_neighbors\":np.arange(1,20)}\n",
    "knn = KNeighborsClassifier()\n",
    "cv_knn = StratifiedKFold(n_splits =10)\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv = cv_knn)\n",
    "knn_cv.fit(train_X, train_y)\n",
    "print(knn_cv.best_params_)\n",
    "print(knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a k-NN classifier with 7 neighbors: knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "\n",
    "# Testing the model in the training phase\n",
    "cv_knn = StratifiedKFold(n_splits =10)\n",
    "scores_knn = cross_val_score(knn, train_X, train_y, cv=cv_knn)\n",
    "accu_knn = scores_knn.mean()\n",
    "print('Accuracy: %0.2f (+/- %0.2f)' % (scores_knn.mean(),scores_knn.std()*2))\n",
    "\n",
    "print(scores_knn)\n",
    "print(mean(scores_knn))\n",
    "# Fit the classifier to the data\n",
    "knn.fit(train_X,train_y)\n",
    "\n",
    "# Predict the labels for the testing data x_val\n",
    "y_pred_knn = knn.predict(test_X).astype(int)\n",
    "\n",
    "# store it in the csv file\n",
    "predict_csv(y_pred_knn,'knn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier #For Classification\n",
    "from sklearn.ensemble import AdaBoostRegressor #For Regression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "DTC = DecisionTreeClassifier()\n",
    "\n",
    "adaB = AdaBoostClassifier(DTC, random_state=7)\n",
    "\n",
    "cv_ada = StratifiedKFold(n_splits =10)\n",
    "\n",
    "param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n",
    "              \"n_estimators\" :[1,2],\n",
    "              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n",
    "\n",
    "\n",
    "adaBoost = GridSearchCV(adaB,param_grid = param_grid, cv=cv_ada, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "adaBoost.fit(train_X,train_y)\n",
    "\n",
    "best_adaB = adaBoost.best_estimator_\n",
    "\n",
    "adaBoost.best_score_\n",
    "\n",
    "accu_ada = adaBoost.best_score_\n",
    "\n",
    "y_pred_ada = best_adaB.predict(test_X).astype(int)\n",
    "\n",
    "# store it in the csv file\n",
    "predict_csv(y_pred_ada, 'adatest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaBoost.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "cv_svc = StratifiedKFold(n_splits =10)\n",
    "clf_svc = SVC(C = 1, kernel = 'linear')\n",
    "scores_svc = cross_val_score(clf_svc, train_X, train_y, cv=cv_svc)\n",
    "accu_svc = scores_svc.mean()\n",
    "\n",
    "# train the model using the whole training dataset\n",
    "clf_svc.fit(train_X,train_y)\n",
    "# predict the labels of test dataset\n",
    "y_pred_svc =clf_svc.predict(test_X).astype(int)\n",
    "\n",
    "# store it in the csv file\n",
    "predict_csv(y_pred_svc, 'svc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 Model Selection and Label Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Model comparison and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we integrate the accuracy of different models\n",
    "model_name = pd.Series(['DecisionTree', 'RandomForest', 'LogisticRegression', 'KNN', 'Adaboost','SVC'])\n",
    "accu_train = pd.Series([accu_dt, accu_rf, accu_logreg, accu_knn, accu_ada, accu_svc])\n",
    "score_kaggle = pd.Series([0.78947,0.77990,0.77033,0.67942,0.79425,0.76555])\n",
    "Model_performance = pd.concat([model_name, accu_train, score_kaggle],axis =1)\n",
    "Model_performance.columns = ['Model', 'TrainAccuracy', 'ScoreKaggle']\n",
    "Model_performance.sort_values(by='ScoreKaggle', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest has the highest training accuracy, while Adaboost gains the best score on Kaggle. Therefore, we will take a look at the feature importance on both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Feature importance in RamdomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance for each feature using Logistic Regression\n",
    "feature_rf = pd.Series(clf_rf.feature_importances_)\n",
    "feature_name= pd.Series(train_X.columns.values.tolist())\n",
    "Feature_imp_rf = pd.concat([feature_name,feature_rf],axis =1)\n",
    "Feature_imp_rf.columns = ['Feature', 'ImportanceScore']\n",
    "Feature_imp_rf = Feature_imp_rf.sort_values(by='ImportanceScore', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "g = sns.barplot(y = Feature_imp_rf.loc[:,'Feature'], x = Feature_imp_rf.loc[:,'ImportanceScore'], orient='h')\n",
    "g.set_xlabel('relative importance')\n",
    "g.set_ylabel('features')\n",
    "g.tick_params(labelsize=9)\n",
    "g.set_title('RandomForest Feature Importance' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Feature importance in Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance for each feature using Logistic Regression\n",
    "feature_ada = pd.Series(best_adaB.feature_importances_)\n",
    "Feature_imp_ada = pd.concat([feature_name,feature_ada],axis =1)\n",
    "Feature_imp_ada.columns = ['Feature', 'ImportanceScore']\n",
    "Feature_imp_ada = Feature_imp_ada.sort_values(by='ImportanceScore', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "g = sns.barplot(y = Feature_imp_ada.loc[:,'Feature'], x = Feature_imp_ada.loc[:,'ImportanceScore'], orient='h')\n",
    "g.set_xlabel('relative importance')\n",
    "g.set_ylabel('features')\n",
    "g.tick_params(labelsize=9)\n",
    "g.set_title('AdaBoost Feature Importance' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Use Voting Classifier to Combine Models\n",
    "Since RandomForest gets the highest training accuracy among all models and Adaboost gets the highest score on Kaggle, we decide to use Voting classifier to integrate these two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "votingC = VotingClassifier(estimators=[('rf', clf_rf), ('adaboost', best_adaB)], voting='soft', n_jobs=4)\n",
    "\n",
    "votingC = votingC.fit(train_X, train_y)\n",
    "\n",
    "# Predict the labels in test_X\n",
    "y_pred_vot = votingC.predict(test_X).astype(int)\n",
    "\n",
    "# stroe it in the csv file\n",
    "predict_csv(y_pred_vot, 'Vot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
